// ì‚¬ì£¼ ê³ ì„œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ Supabaseì— ì—…ë¡œë“œ
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import OpenAI from 'openai';
import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';

// ES moduleì—ì„œ __dirname ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì •
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
dotenv.config({ path: path.join(__dirname, '..', '.env.local') });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
);

// í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° (ì„¹ì…˜ ê¸°ì¤€)
function splitIntoChunks(text, source) {
  const chunks = [];

  // ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ([ ] ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ê¸°ì¤€ìœ¼ë¡œ)
  const sections = text.split(/\n(?=\[)/);

  sections.forEach((section) => {
    section = section.trim();
    if (section.length < 50) return; // ë„ˆë¬´ ì§§ì€ ì„¹ì…˜ì€ ì œì™¸

    // ì„¹ì…˜ëª… ì¶”ì¶œ
    const sectionMatch = section.match(/^\[([^\]]+)\]/);
    const sectionName = sectionMatch ? sectionMatch[1] : 'ë¯¸ë¶„ë¥˜';

    // ì²­í¬ê°€ ë„ˆë¬´ í¬ë©´ ë” ì‘ê²Œ ë‚˜ëˆ„ê¸° (ì•½ 1000ì ê¸°ì¤€)
    if (section.length > 1500) {
      const paragraphs = section.split(/\n\n+/);
      let currentChunk = '';
      let currentSection = sectionName;

      paragraphs.forEach((para) => {
        if ((currentChunk + para).length > 1500 && currentChunk.length > 0) {
          chunks.push({
            content: currentChunk.trim(),
            metadata: { section: currentSection }
          });
          currentChunk = para;
        } else {
          currentChunk += (currentChunk ? '\n\n' : '') + para;
        }
      });

      if (currentChunk.trim()) {
        chunks.push({
          content: currentChunk.trim(),
          metadata: { section: currentSection }
        });
      }
    } else {
      chunks.push({
        content: section,
        metadata: { section: sectionName }
      });
    }
  });

  return chunks;
}

// ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
async function generateEmbeddings(texts) {
  console.log(`ì„ë² ë”© ìƒì„± ì¤‘: ${texts.length}ê°œ ì²­í¬`);

  // OpenAI APIëŠ” ë°°ì¹˜ ìš”ì²­ì„ ì§€ì›í•˜ì§€ë§Œ, í•œë²ˆì— ë„ˆë¬´ ë§ìœ¼ë©´ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆíˆ ë‚˜ëˆ„ê¸°
  const batchSize = 50;
  const embeddings = [];

  for (let i = 0; i < texts.length; i += batchSize) {
    const batch = texts.slice(i, i + batchSize);
    console.log(`  ë°°ì¹˜ ${Math.floor(i / batchSize) + 1}/${Math.ceil(texts.length / batchSize)} ì²˜ë¦¬ ì¤‘...`);

    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: batch,
    });

    embeddings.push(...response.data.map(item => item.embedding));

    // API rate limitì„ ê³ ë ¤í•œ ë”œë ˆì´
    if (i + batchSize < texts.length) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }

  return embeddings;
}

// Supabaseì— ì—…ë¡œë“œ
async function uploadToSupabase(source, chunks, embeddings) {
  console.log(`\n${source} Supabaseì— ì—…ë¡œë“œ ì¤‘...`);

  const rows = chunks.map((chunk, i) => ({
    source,
    content: chunk.content,
    embedding: embeddings[i],
    metadata: chunk.metadata
  }));

  // ë°°ì¹˜ ì—…ë¡œë“œ (1000ê°œì”©)
  const batchSize = 1000;
  for (let i = 0; i < rows.length; i += batchSize) {
    const batch = rows.slice(i, i + batchSize);
    const { error } = await supabase
      .from('saju_chunks')
      .insert(batch);

    if (error) {
      console.error(`âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ (ë°°ì¹˜ ${i / batchSize + 1}):`, error);
      throw error;
    }

    console.log(`  âœ… ${i + batch.length}/${rows.length} ì—…ë¡œë“œ ì™„ë£Œ`);
  }
}

// ë©”ì¸ í•¨ìˆ˜
async function main() {
  console.log('ğŸš€ ì‚¬ì£¼ ê³ ì„œ ì„ë² ë”© ì—…ë¡œë“œ ì‹œì‘\n');

  const books = [
    { file: 'ìí‰ì§„ì „.txt', source: 'ìí‰ì§„ì „' },
    { file: 'ê¶í†µë³´ê°.txt', source: 'ê¶í†µë³´ê°' },
    { file: 'ì ì²œìˆ˜.txt', source: 'ì ì²œìˆ˜' }
  ];

  for (const book of books) {
    console.log(`\n${'='.repeat(50)}`);
    console.log(`ğŸ“– ${book.source} ì²˜ë¦¬ ì¤‘...`);
    console.log('='.repeat(50));

    // 1. í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
    const filePath = path.join(__dirname, '..', 'data', book.file);
    const text = fs.readFileSync(filePath, 'utf-8');
    console.log(`âœ… íŒŒì¼ ì½ê¸° ì™„ë£Œ: ${(text.length / 1024).toFixed(1)}KB`);

    // 2. ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    const chunks = splitIntoChunks(text, book.source);
    console.log(`âœ… ì²­í¬ ë¶„í•  ì™„ë£Œ: ${chunks.length}ê°œ`);

    // 3. ì„ë² ë”© ìƒì„±
    const texts = chunks.map(c => c.content);
    const embeddings = await generateEmbeddings(texts);
    console.log(`âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: ${embeddings.length}ê°œ`);

    // 4. Supabase ì—…ë¡œë“œ
    await uploadToSupabase(book.source, chunks, embeddings);
    console.log(`âœ… ${book.source} ì—…ë¡œë“œ ì™„ë£Œ!\n`);
  }

  console.log('\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!');
  console.log('\në‹¤ìŒ ë‹¨ê³„:');
  console.log('1. Supabaseì—ì„œ ë°ì´í„° í™•ì¸: SELECT COUNT(*), source FROM saju_chunks GROUP BY source;');
  console.log('2. ê°œë°œ ì„œë²„ ì¬ì‹œì‘ í›„ í…ŒìŠ¤íŠ¸');
}

// ì‹¤í–‰
main().catch(error => {
  console.error('âŒ ì˜¤ë¥˜ ë°œìƒ:', error);
  process.exit(1);
});
