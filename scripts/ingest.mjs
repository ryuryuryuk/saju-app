import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
);

async function getEmbedding(text) {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text,
  });
  return response.data[0].embedding;
}

// --- ì ì²œìˆ˜ ì²­í‚¹ ---
function chunkì ì²œìˆ˜(text) {
  const chunks = [];
  // Split by section headers: [ì ì²œìˆ˜: ì„¹ì…˜ëª…]
  const sectionRegex = /\[ì ì²œìˆ˜:\s*(.+?)\]/g;
  const sectionMatches = [...text.matchAll(sectionRegex)];

  for (let i = 0; i < sectionMatches.length; i++) {
    const sectionName = sectionMatches[i][1].trim();
    const start = sectionMatches[i].index;
    const end = i + 1 < sectionMatches.length ? sectionMatches[i + 1].index : text.length;
    const sectionText = text.slice(start, end).trim();

    // Split section by numbered subsections (1. 2. 3.)
    const subSections = sectionText.split(/(?=^\d+\.\s)/m).filter(s => s.trim().length > 50);

    if (subSections.length <= 1) {
      // No subsections or single block - keep as one chunk
      chunks.push({
        content: sectionText,
        metadata: {
          source: 'ì ì²œìˆ˜',
          section: sectionName,
          type: 'classical_theory',
        },
      });
    } else {
      for (const sub of subSections) {
        const trimmed = sub.trim();
        if (trimmed.length < 50) continue;
        // Extract subsection title from first line
        const firstLine = trimmed.split('\n')[0].trim();
        chunks.push({
          content: trimmed,
          metadata: {
            source: 'ì ì²œìˆ˜',
            section: sectionName,
            subsection: firstLine.slice(0, 60),
            type: 'classical_theory',
          },
        });
      }
    }
  }

  // Also capture the ì¢…í•©/ê°€ì´ë“œ sections and ì¶”ê°€ìë£Œ
  const guideRegex = /\[ì¢…í•© ìš”ì•½ ë° ê°€ì´ë“œ\]([\s\S]*?)(?=\[ì ì²œìˆ˜:|$)/g;
  // These are already included within sections above, so skip separate capture.

  return chunks;
}

// --- ê¶í†µë³´ê° ì²­í‚¹ ---
function chunkê¶í†µë³´ê°(text) {
  const chunks = [];

  // Split into two major parts:
  // Part 1: ì˜¤í–‰ ì´ë¡  (sections 1-6: ì˜¤í–‰ì˜ ê¸°ì›, ëª©, í™”, í† , ê¸ˆ, ìˆ˜)
  // Part 2: ì²œê°„ë³„ ì¡°í›„ (sections 1-10: ê°‘ëª©~ê³„ìˆ˜)

  // Find ì²œê°„ sections by pattern like "1. ê°‘ëª©", "2. ì„ëª©", etc. after the general sections
  const heavenlyStemRegex = /^(\d+)\.\s*(ê°‘ëª©|ì„ëª©|ë³‘í™”|ì •í™”|ë¬´í† |ê¸°í† |ê²½ê¸ˆ|ì‹ ê¸ˆ|ì„ìˆ˜|ê³„ìˆ˜)\s*\((.+?)\)/gm;
  const stemMatches = [...text.matchAll(heavenlyStemRegex)];

  // General ì˜¤í–‰ sections (before first ì²œê°„ section)
  const generalSectionRegex = /^(\d+)\.\s*(ì˜¤í–‰ì˜ ê¸°ì›ê³¼ ë³¸ì„±|ëª©\(æœ¨\)ì˜|í™”\(ç«\)ì˜|í† \(åœŸ\)ì˜|ê¸ˆ\(é‡‘\)ì˜|ìˆ˜\(æ°´\)ì˜)/gm;
  const generalMatches = [...text.matchAll(generalSectionRegex)];

  // Element mapping
  const elementMap = {
    'ê°‘ëª©': 'ëª©', 'ì„ëª©': 'ëª©',
    'ë³‘í™”': 'í™”', 'ì •í™”': 'í™”',
    'ë¬´í† ': 'í† ', 'ê¸°í† ': 'í† ',
    'ê²½ê¸ˆ': 'ê¸ˆ', 'ì‹ ê¸ˆ': 'ê¸ˆ',
    'ì„ìˆ˜': 'ìˆ˜', 'ê³„ìˆ˜': 'ìˆ˜',
  };

  // Chunk general ì˜¤í–‰ sections
  const allNumberedSections = text.split(/(?=^\d+\.\s)/m).filter(s => s.trim().length > 50);

  for (const section of allNumberedSections) {
    const trimmed = section.trim();
    if (trimmed.length < 50) continue;

    const firstLine = trimmed.split('\n')[0].trim();

    // Determine if it's a ì²œê°„ or general section
    const stemMatch = firstLine.match(/^\d+\.\s*(ê°‘ëª©|ì„ëª©|ë³‘í™”|ì •í™”|ë¬´í† |ê¸°í† |ê²½ê¸ˆ|ì‹ ê¸ˆ|ì„ìˆ˜|ê³„ìˆ˜)/);

    if (stemMatch) {
      const stemName = stemMatch[1];
      chunks.push({
        content: trimmed,
        metadata: {
          source: 'ê¶í†µë³´ê°',
          section: 'ì›”ë³„_ì¡°í›„',
          heavenly_stem: stemName,
          element: elementMap[stemName] || '',
          type: 'seasonal_guidance',
        },
      });
    } else {
      // General ì˜¤í–‰ section
      const elementMatch = firstLine.match(/(ì˜¤í–‰|ëª©|í™”|í† |ê¸ˆ|ìˆ˜)/);
      const sectionName = firstLine.slice(0, 40);
      chunks.push({
        content: trimmed,
        metadata: {
          source: 'ê¶í†µë³´ê°',
          section: sectionName,
          type: 'element_theory',
        },
      });
    }
  }

  return chunks;
}

// --- ìí‰ì§„ì „ ì²­í‚¹ ---
function chunkìí‰ì§„ì „(text) {
  const chunks = [];

  // Split by section headers: [ìí‰ì§„ì „: ì„¹ì…˜ëª…]
  const sectionRegex = /\[ìí‰ì§„ì „:\s*(.+?)\]/g;
  const sectionMatches = [...text.matchAll(sectionRegex)];

  for (let i = 0; i < sectionMatches.length; i++) {
    const sectionName = sectionMatches[i][1].trim();
    const start = sectionMatches[i].index;
    const end = i + 1 < sectionMatches.length ? sectionMatches[i + 1].index : text.length;
    const sectionText = text.slice(start, end).trim();

    // Split by numbered subsections
    const subSections = sectionText.split(/(?=^\d+\.\s)/m).filter(s => s.trim().length > 50);

    if (subSections.length <= 1) {
      chunks.push({
        content: sectionText,
        metadata: {
          source: 'ìí‰ì§„ì „',
          section: sectionName,
          type: 'classical_theory',
        },
      });
    } else {
      for (const sub of subSections) {
        const trimmed = sub.trim();
        if (trimmed.length < 50) continue;
        const firstLine = trimmed.split('\n')[0].trim();
        chunks.push({
          content: trimmed,
          metadata: {
            source: 'ìí‰ì§„ì „',
            section: sectionName,
            subsection: firstLine.slice(0, 60),
            type: 'classical_theory',
          },
        });
      }
    }
  }

  return chunks;
}

async function ingest() {
  const dataDir = path.join(process.cwd(), 'data');

  console.log('ğŸ“š ê³ ì„œ í…ìŠ¤íŠ¸ ë¡œë”© ì¤‘...');

  const ì ì²œìˆ˜Text = fs.readFileSync(path.join(dataDir, 'ì ì²œìˆ˜.txt'), 'utf-8');
  const ê¶í†µë³´ê°Text = fs.readFileSync(path.join(dataDir, 'ê¶í†µë³´ê°.txt'), 'utf-8');
  const ìí‰ì§„ì „Text = fs.readFileSync(path.join(dataDir, 'ìí‰ì§„ì „.txt'), 'utf-8');

  console.log(`  ì ì²œìˆ˜: ${ì ì²œìˆ˜Text.length}ì`);
  console.log(`  ê¶í†µë³´ê°: ${ê¶í†µë³´ê°Text.length}ì`);
  console.log(`  ìí‰ì§„ì „: ${ìí‰ì§„ì „Text.length}ì`);

  // Chunk all texts
  const allChunks = [
    ...chunkì ì²œìˆ˜(ì ì²œìˆ˜Text),
    ...chunkê¶í†µë³´ê°(ê¶í†µë³´ê°Text),
    ...chunkìí‰ì§„ì „(ìí‰ì§„ì „Text),
  ];

  console.log(`\nâœ‚ï¸  ì´ ${allChunks.length}ê°œ ì²­í¬ ìƒì„±ë¨`);
  for (const chunk of allChunks) {
    console.log(`  [${chunk.metadata.source}] ${chunk.metadata.section} (${chunk.content.length}ì)`);
  }

  // Clear existing data
  console.log('\nğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...');
  const { error: deleteError } = await supabase.from('saju_chunks').delete().neq('id', 0);
  if (deleteError) {
    console.warn('  ì‚­ì œ ê²½ê³  (í…Œì´ë¸”ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ):', deleteError.message);
  }

  // Embed and upload
  console.log('\nğŸ”„ ì„ë² ë”© ë° ì—…ë¡œë“œ ì‹œì‘...');
  let successCount = 0;

  for (let i = 0; i < allChunks.length; i++) {
    const chunk = allChunks[i];
    try {
      console.log(`  [${i + 1}/${allChunks.length}] ì„ë² ë”© ì¤‘: ${chunk.metadata.source} - ${chunk.metadata.section}`);

      const embedding = await getEmbedding(chunk.content);

      const { error } = await supabase.from('saju_chunks').insert({
        content: chunk.content,
        embedding,
        metadata: chunk.metadata,
      });

      if (error) {
        console.error(`  âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: ${error.message}`);
      } else {
        successCount++;
      }

      // Rate limiting: small delay between requests
      if (i < allChunks.length - 1) {
        await new Promise(r => setTimeout(r, 200));
      }
    } catch (err) {
      console.error(`  âŒ ì—ëŸ¬: ${err.message}`);
    }
  }

  console.log(`\nâœ… ì™„ë£Œ! ${successCount}/${allChunks.length}ê°œ ì²­í¬ ì—…ë¡œë“œ ì„±ê³µ`);
}

ingest().catch(console.error);
